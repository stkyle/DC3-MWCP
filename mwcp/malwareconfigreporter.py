"""
    DC3-MWCP framework primary object used for execution of parsers and collection of metadata
"""
import base64
import cStringIO
import glob
import hashlib
import inspect
import json
import ntpath
import os
import pkgutil
import re
import shutil
import sys
import tempfile
import traceback

from mwcp.malwareconfigparser import malwareconfigparser

# pefile is now strictly optional, loaded down below so we can use reporter for error reporting

INFO_FIELD_ORDER = ['inputfilename', 'md5', 'sha1', 'sha256', 'compiletime']
STANDARD_FIELD_ORDER = ["c2_url", "c2_socketaddress", "c2_address", "url", "urlpath",
                        "socketaddress", "address", "port", "listenport",
                        "credential", "username", "password",
                        "missionid", "useragent", "interval", "version", "mutex",
                        "service", "servicename", "servicedisplayname", "servicedescription",
                        "serviceimage", "servicedll", "injectionprocess",
                        "filepath", "directory", "filename",
                        "registrykeyvalue", "registrykey", "registryvalue", "key"]


# noinspection PyPep8Naming
class malwareconfigreporter(object):
    """
    Class for doing heavy lifting of parser execution and metadata reporting

    This class contains state and data about the current config parsing run, including extracted metadata,
    holding the actual sample, etc.

    Re-using an instance of this class on multiple samples is possible and should be safe, but it is not
    recommended

    Parameters:
        parserdir: sets attribute
        resourcedir: sets attribute
        tempdir: sets attribute
        outputdir: sets directory for output_file(). Should not be written to (or read from) by parsers
            directly (use tempdir)
        outputfile_prefix: sets prefix for output files written to outputdir. Special value "md5" causes
            prefix by md5 of the input file.
        interpreter_path: overrides value returned by interpreter_path()
        disabledebug: disable inclusion of debug messages in output
        disableoutputfiles: disable writing if files to filesystem
        disabletempcleanup: disable cleanup (deletion) of temp files
        disableautosubfieldparsing: disable parsing of metadata item of subfields
        disablevaluededup: disable deduplication of metadata items
        disablemodulesearch: disable search of modules for parsers, only look in parsers directory

    Attributes:
        parserdir: Directory where parsers reside. This directory is added to python path. This should not be
            changed except through constructor and parsers should have no reason to read this value.
        resourcedir: Directory where resources reside. This directory is added to python path and PYTHONPATH
            env variable. This should not be changed except through constructor and parsers should have no
            reason to read this value.
        tempdir: directory where temporary files should be created. Files created in this directory should
            be deleted by parser. See managed_tempdir for mwcp managed directory
        data: buffer containing input file to parsed
        handle: file handle (stringio) of file to parsed
        metadata: Dictionary containing the metadata extracted from the malware by the parser
        pe: a pefile object, assuming pefile is installed and succesful parsing of file
        outputfiles: dictionary of entries for each ouput file. The key is the filename specified. Each entry
            is a dictionary with keys of data and description. If the path key is set, the file was written
            to that path on the filesystem.
        fields: dictionary containing the standardized fields with each field comprising an embedded
            dictionary. The 1st level keys are the field names. Under that, the keys are "description",
            "examples", and "type". See fields.json.
        errors: list of errors generated by framework. Generally parsers should not set these, they should
            use debug instead

    """

    # changing this is not recommended
    __parsernamepostfix = "_malwareconfigparser"

    def __init__(self,
                 parserdir=None,
                 resourcedir=None,
                 outputdir=None,
                 tempdir=None,
                 outputfile_prefix=None,
                 interpreter_path=None,
                 disabledebug=False,
                 disableoutputfiles=False,
                 disabletempcleanup=False,
                 disableautosubfieldparsing=False,
                 disablevaluededup=False,
                 disablemodulesearch=False,
                 base64outputfiles=False,
                 ):

        # defaults
        self.parserdir = os.path.join(os.path.dirname(__file__), "parsers")
        self.resourcedir = os.path.join(os.path.dirname(__file__), "resources")
        self.tempdir = tempfile.gettempdir()
        self.outputfiles = {}
        self.data = ''
        self.handle = None
        self.fields = {"debug": {"description": "debug", "type": "listofstrings"}}
        self.metadata = {}
        self.errors = []
        self.pe = None

        self.__debug_stdout = None
        self.__orig_stdout = None
        self.__filename = ''
        self.__tempfilename = ''
        self.__managed_tempdir = ''
        self.__outputdir = ''
        self.__outputfile_prefix = ''

        if parserdir:
            self.parserdir = parserdir
        if resourcedir:
            self.resourcedir = resourcedir
        if outputdir:
            self.__outputdir = outputdir
        if tempdir:
            self.tempdir = tempdir
        if outputfile_prefix:
            self.__outputfile_prefix = outputfile_prefix

        if self.parserdir not in sys.path:
            sys.path.append(self.parserdir)
        if self.resourcedir not in sys.path:
            sys.path.append(self.resourcedir)

        # we put resourcedir in PYTHONPATH in case we shell out or children processes need this
        if 'PYTHONPATH' in os.environ:
            if self.resourcedir not in os.environ['PYTHONPATH']:
                os.environ['PYTHONPATH'] = os.environ['PYTHONPATH'] + os.pathsep + self.resourcedir
        else:
            os.environ['PYTHONPATH'] = self.resourcedir

        self.__interpreter_path = interpreter_path
        self.__disabledebug = disabledebug
        self.__disableoutputfiles = disableoutputfiles
        self.__disabletempcleanup = disabletempcleanup
        self.__disableautosubfieldparsing = disableautosubfieldparsing
        self.__disablevaluededup = disablevaluededup
        self.__disablemodulesearch = disablemodulesearch
        self.__base64outputfiles = base64outputfiles

        self.__orig_stdout = sys.stdout

        fieldspath = os.path.join(self.resourcedir, "fields.json")

        with open(fieldspath, 'rb') as f:
            self.fields = json.load(f)

    def filename(self):
        """get the input file name.

        Note:
            If input was not a filesystem object, we create a temp file that is removed after parser is
            finished (unless tempcleanup is disabled).
        """
        if self.__filename:
            # we were given a filename, give it back
            return self.__filename
        else:
            # we were passed data buffer. Lazy initialize a temp file for this
            if not self.__tempfilename:
                with tempfile.NamedTemporaryFile(delete=False, dir=self.tempdir, prefix="mwcp-inputfile-") as tfile:
                    tfile.write(self.data)
                    self.__tempfilename = tfile.name

                if self.__disabletempcleanup:
                    self.debug("Using tempfile as input file: %s" % self.__tempfilename)

            return self.__tempfilename

    def managed_tempdir(self):
        """Returns the filename of a managed temporary directory.
        Note:
            This directory will be deleted when parser is finished, unless tempcleanup is disabled.
        """

        if not self.__managed_tempdir:
            self.__managed_tempdir = tempfile.mkdtemp(dir=self.tempdir, prefix="mwcp-managed_tempdir-")

            if self.__disabletempcleanup:
                self.debug("Using managed temp dir: %s" % self.__managed_tempdir)

        return self.__managed_tempdir

    def interpreter_path(self):
        """Returns the path for python interpreter, assuming it can be found.
        Note:
            Because of various factors (inlcuding ablity to override) this may not be accurate.

        """
        if not self.__interpreter_path:
            # first try sys.executable--this is reliable most of the time but doesn't work
            # when python is embedded, ex. using wsgi mod for web server
            if "python" in os.path.basename(sys.executable):
                self.__interpreter_path = sys.executable
            # second try sys.prefix and common executable names
            else:
                possible_path = os.path.join(sys.prefix, "python.exe")
                if os.path.exists(possible_path):
                    self.__interpreter_path = possible_path
                possible_path = os.path.join(sys.prefix, "bin", "python")
                if os.path.exists(possible_path):
                    self.__interpreter_path = possible_path
                    # other options to consider:
                    # look at some library paths, such as os.__file__, use system path to
                    # find python executable that uses that library
                    # use shell and let it find python. Ex. which python
        return self.__interpreter_path

    def error(self, message):
        """Record an error message
        Args:
            message (str): error message. Note: typically only framework reports error and parsers report via debug
        """
        self.errors.append(message)

    def debug(self, message):
        """Record a debug message
        Args:
            message (str): debug message. Note: typically parsers report via debug
        """
        if not self.__disabledebug:
            self.add_metadata("debug", message)

    def __add_metatadata_listofstrings(self, keyu, value):

        try:
            valueu = self.convert_to_unicode(value)
            if keyu not in self.metadata:
                self.metadata[keyu] = []
            if valueu not in self.metadata[keyu] or self.__disablevaluededup:
                self.metadata[keyu].append(valueu)

            if not self.__disableautosubfieldparsing:
                if keyu == "filepath":
                    # use ntpath instead of os.path so we are consistant across platforms. ntpath should
                    # work for both windows and unix paths.
                    # os.path works for the platform you are running on, not necessarily what the malware
                    # was written for.
                    # Ex. when running mwcp on linux to process windows malware, os.path will fail due
                    # to not handling backslashes correctly.
                    self.add_metadata("filename", ntpath.basename(valueu))
                    self.add_metadata("directory", ntpath.dirname(valueu))
                if keyu == "c2_url":
                    self.add_metadata("url", valueu)
                if keyu == "c2_address":
                    self.add_metadata("address", valueu)
                if keyu == "serviceimage":
                    # we use tactic of looking for first .exe in value. This is not guaranteed to be reliable
                    if '.exe' in valueu:
                        self.add_metadata("filepath", valueu[0:valueu.find('.exe') + 4])
                if keyu == "servicedll":
                    self.add_metadata("filepath", valueu)
                if keyu == "url" or keyu == "c2_url":
                    # http://[fe80::20c:1234:5678:9abc]:80/badness
                    # http://bad.com:80
                    # ftp://127.0.0.1/really/bad?hostname=pwned
                    match = re.search(r"[a-z\.-]{1,40}://(\[?[^/]+\]?)(/[^?]+)?", valueu)
                    if match:
                        if match.group(1):
                            address = match.group(1)
                            if address[0] == "[":
                                # ipv6--something like [fe80::20c:1234:5678:9abc]:80
                                parts = address.split("]")
                                if len(parts) > 1:
                                    if parts[1]:
                                        if keyu == "c2_url":
                                            self.add_metadata("c2_socketaddress", [parts[0][1:], parts[1][1:], "tcp"])
                                        else:
                                            self.add_metadata("socketaddress", [parts[0][1:], parts[1][1:], "tcp"])
                                else:
                                    if keyu == "c2_url":
                                        self.add_metadata("c2_address", parts[0][1:])
                                    else:
                                        self.add_metadata("address", parts[0][1:])
                            else:
                                # regular domain or ipv4--bad.com:80 or 127.0.0.1
                                parts = address.split(":")
                                if len(parts) > 1:
                                    if parts[1]:
                                        if keyu == "c2_url":
                                            self.add_metadata("c2_socketaddress", [parts[0], parts[1], "tcp"])
                                        else:
                                            self.add_metadata("socketaddress", [parts[0], parts[1], "tcp"])
                                else:
                                    if keyu == "c2_url":
                                        self.add_metadata("c2_address", parts[0])
                                    else:
                                        self.add_metadata("address", parts[0])
                        if match.group(2):
                            self.add_metadata("urlpath", match.group(2))
                    else:
                        self.debug("Error parsing as url: %s" % valueu)

        except Exception as e:
            self.debug("Error adding metadata for key: %s\n%s" % (keyu, traceback.format_exc()))

    def __add_metadata_listofstringtuples(self, keyu, value):
        try:
            values = []
            if not value:
                self.debug("no values provided for %s, skipping" % keyu)
                return
            for thisvalue in value:
                values.append(self.convert_to_unicode(thisvalue))

            if keyu not in self.metadata:
                self.metadata[keyu] = []
            if self.__disablevaluededup:
                self.metadata[keyu].append(values)
            else:
                try:
                    dedupindex = self.metadata[keyu].index(values)
                except ValueError:
                    self.metadata[keyu].append(values)

            if not self.__disableautosubfieldparsing:
                # TODO: validate lengths for known types
                if keyu == "c2_socketaddress":
                    self.add_metadata("socketaddress", values)
                    self.add_metadata("c2_address", values[0])
                elif keyu == "socketaddress":
                    self.add_metadata("address", values[0])
                    if len(values) >= 3:
                        self.add_metadata("port", [values[1], values[2]])
                    if len(values) != 3:
                        self.debug("Expected three values in type socketaddress, received %i" % len(values))
                elif keyu == "credential":
                    self.add_metadata("username", values[0])
                    if len(values) >= 2:
                        self.add_metadata("password", values[1])
                    if len(values) != 2:
                        self.debug("Expected two values in type credential, received %i" % len(values))
                elif keyu == "port" or keyu == "listenport":
                    if len(values) != 2:
                        self.debug("Expected two values in type %s, received %i" % (keyu, len(values)))
                    # check for integer number and valid proto?
                    match = re.search(r"[0-9]{1,5}", values[0])
                    if match:
                        portnum = int(values[0])
                        if portnum < 0 or portnum > 65535:
                            self.debug("Expected port to be number between 0 and 65535")
                    else:
                        self.debug("Expected port to be number between 0 and 65535")
                    if len(values) >= 2:
                        if values[1] not in ["tcp", "udp", "icmp"]:
                            self.debug("Expected port type to be tcp or udp (or icmp)")
                elif keyu == "registrykeyvalue":
                    self.add_metadata("registrykey", values[0])
                    if len(values) >= 2:
                        self.add_metadata("registryvalue", values[1])
                    if len(values) != 2:
                        self.debug("Expected two values in type registrykeyvalue, received %i" % len(values))
                elif keyu == "service":
                    if values[0]:
                        self.add_metadata("servicename", values[0])
                    if len(values) >= 2:
                        if values[1]:
                            self.add_metadata("servicedisplayname", values[1])
                    if len(values) >= 3:
                        if values[2]:
                            self.add_metadata("servicedescription", values[2])
                    if len(values) >= 4:
                        if values[3]:
                            self.add_metadata("serviceimage", values[3])
                    if len(values) >= 5:
                        if values[4]:
                            self.add_metadata("servicedll", values[4])

                    if len(values) != 5:
                        self.debug("Expected 5 values in type service, received %i" % len(values))

        except Exception as e:
            self.debug("Error adding metadata for key: %s\n%s" % (keyu, traceback.format_exc()))

    def __add_metadata_dictofstrings(self, keyu, value):
        try:
            # check for type of other?
            for thiskey in value:
                if isinstance(value[thiskey], basestring):
                    thiskeyu = self.convert_to_unicode(thiskey)
                    thisvalueu = self.convert_to_unicode(value[thiskey])
                    if 'other' not in self.metadata:
                        self.metadata['other'] = {}
                    if thiskeyu in self.metadata['other']:
                        # this key already exists, we don't want to clobber so we turn into list?
                        existingvalue = self.metadata['other'][thiskeyu]
                        if isinstance(existingvalue, list):
                            if thisvalueu not in self.metadata['other'][thiskeyu]:
                                self.metadata['other'][thiskeyu].append(thisvalueu)
                        else:
                            if thisvalueu != existingvalue:
                                self.metadata['other'][thiskeyu] = [existingvalue, thisvalueu]
                    else:
                        # normal insert of single value
                        self.metadata['other'][thiskeyu] = thisvalueu
                else:
                    # TODO: support inserts of lists (assuming members are strings)?
                    self.debug("Could not add object of %s to metadata under other using key %s" % (
                        str(type(value[thiskey])), thiskey))
        except Exception as e:
            self.debug("Error adding metadata for key: %s\n%s" % (keyu, traceback.format_exc()))

    def add_metadata(self, key, value):
        """
        Report a metadata item

        Primary method to report metadata as a result of parsing.

        Args:
            key: string specifying the key of the metadata. Should be one of values specified in fields.json.
            value: string specifying the value of the metadata. Should be a utf-8 encoded string or a unicode object.

        """

        try:
            keyu = self.convert_to_unicode(key)
        except Exception as e:
            self.debug("Error adding metadata due to failure converting key to unicode: %s" % (traceback.format_exc()))
            return

        if keyu in self.fields:
            fieldtype = self.fields[keyu]['type']
        else:
            self.debug("Error adding metadata because %s is not an allowed key" % keyu)
            return

        if fieldtype == "listofstrings":
            self.__add_metatadata_listofstrings(keyu, value)

        if fieldtype == "listofstringtuples":
            self.__add_metadata_listofstringtuples(keyu, value)

        if fieldtype == "dictofstrings":
            self.__add_metadata_dictofstrings(keyu, value)

    @staticmethod
    def convert_to_unicode(input_string):
        if isinstance(input_string, unicode):
            return input_string
        else:
            return unicode(input_string, encoding='utf8', errors='replace')

    def list_parsers(self):
        """
        Retrieve list of parsers
        """
        parsers = []

        if self.__disablemodulesearch:
            # We only look for .py files--it is much better to use regualr module search
            parser_file_postfix = self.__parsernamepostfix + '.py'
            for fullpath in glob.glob(os.path.join(self.parserdir, '*' + parser_file_postfix)):
                basefile = os.path.basename(fullpath)
                parsers.append(basefile[:-len(parser_file_postfix)])
        else:
            for loader, modulename, ispkg in pkgutil.iter_modules():
                if not ispkg:
                    if modulename[-len(self.__parsernamepostfix):] == self.__parsernamepostfix and len(
                            modulename) > len(self.__parsernamepostfix):
                        parsers.append(modulename[:-len(self.__parsernamepostfix)])

        return parsers

    def load_parser_instance(self, name):
        """Load parser instance by parser name
        Args:
            name (str): parser name
        """
        try:
            parserobj = None

            # we use __import__ instead of importlib.import_module because we want to work on 2.6
            parser = __import__("%s%s" % (name, self.__parsernamepostfix))

            # find descendants of malwareconfigparser in this module, instantiate it
            for c in parser.__dict__.values():
                if inspect.isclass(c):
                    if malwareconfigparser in c.__bases__:
                        parserobj = c(reporter=self)
                        return parserobj
            # not found
            self.error("Could not locate parser object in module %s" % name)

        except (Exception, SystemExit) as e:
            self.error("Error loading parser %s: %s" % (name, traceback.format_exc()))

    def get_parser_descriptions(self):
        """
        Retrieve list of parser descriptions

        Returns list of tuples per parser. Tuple contains parser name, author, and description.
        """
        try:
            self.__redirect_stdout()
            descriptions = []
            for parsername in self.list_parsers():
                parserobj = self.load_parser_instance(parsername)
                if parserobj:
                    descriptions.append((parsername, parserobj.author, parserobj.description))
            self.__return_stdout()
            return descriptions
        except (Exception, SystemExit) as e:
            self.__return_stdout()
            self.error("Error getting parser descriptions: %s" % (traceback.format_exc()))
            return []

    def run_parser(self, name, filename=None, data="", **kwargs):
        """
        Runs specified parser on file

        Args:
            name: name of parser module to run
            filename: file to parse
            data: use data as file instead of loading data from filename
        """

        self.__redirect_stdout()

        try:

            self.__reset()

            if filename:
                self.__filename = filename
                with open(self.__filename, 'rb') as f:
                    self.data = f.read()
            else:
                self.data = data

            self.handle = cStringIO.StringIO(self.data)

            if self.data[:2] == "MZ":
                # We try to import pefile here because we want pefile to be optional
                # We create pefile object from input file if we can
                # We want to be able to catch import error and log it using reporter object.
                try:
                    import pefile
                    try:
                        self.pe = pefile.PE(data=self.data)
                    except Exception as e:
                        self.debug("Error parsing with pefile: %s" % (str(e)))
                except ImportError:
                    self.debug("Could not import pefile")

            parserobj = self.load_parser_instance(name)
            if parserobj:
                # now set in constructor
                # parserobj.reporter = self
                parserobj.run(**kwargs)

            self.__return_stdout()
            self.__cleanup()

        except (Exception, SystemExit) as e:
            if filename:
                identifier = filename
            else:
                identifier = hashlib.md5(data).hexdigest()
            self.__return_stdout()
            self.__cleanup()
            self.error("Error running parser %s on %s: %s" % (name, identifier, traceback.format_exc()))

    @staticmethod
    def pprint(data):
        """JSON Pretty Print data
        Args:
            data: XXX
        """
        return json.dumps(data, indent=4)

    def output_file(self, data, filename, description=''):
        """Report a file created by the parser
        
        This should involve a file created by the parser and related to the malware.
        
        Args:
            data: The contents of the output file
            filename: filename (basename) of file
            description: description of the file
        """
        self.outputfiles[filename] = {'data': data, 'description': description}
        basename = os.path.basename(filename)

        if self.__base64outputfiles:
            self.add_metadata("outputfile", [basename, description, base64.b64encode(data)])
        else:
            self.add_metadata("outputfile", [basename, description])

        if self.__disableoutputfiles:
            return

        if self.__outputfile_prefix:
            if self.__outputfile_prefix == "md5":
                fullpath = os.path.join(self.__outputdir, "%s_%s" % (hashlib.md5(self.data).hexdigest(), basename))
            else:
                fullpath = os.path.join(self.__outputdir, "%s_%s" % (self.__outputfile_prefix, basename))
        else:
            fullpath = os.path.join(self.__outputdir, basename)

        try:
            with open(fullpath, "wb") as f:
                f.write(data)
            self.debug("outputfile: %s" % fullpath)
            self.outputfiles[filename]['path'] = fullpath
        except Exception as e:
            self.debug("Failed to write output file: %s, %s" % (fullpath, str(e)))

    def report_tempfile(self, filename, description=''):
        """load filename from filesystem and report using output_file
        Args:
            filename
            description
        """
        if os.path.isfile(filename):
            with open(filename, "rb") as f:
                data = f.read()
            self.output_file(data, os.path.basename(filename), description)
        else:
            self.debug("Could not output file because it could not be found: %s" % filename)

    @staticmethod
    def format_list(values, key=None):

        if key == "credential" and len(values) == 2:
            return "%s:%s" % (values[0], values[1])
        elif key == "outputfile" and len(values) >= 2:
            return "%s %s" % (values[0], values[1])
        elif key == "port" and len(values) == 2:
            return "%s/%s" % (values[0], values[1])
        elif key == "listenport" and len(values) == 2:
            return "%s/%s" % (values[0], values[1])
        elif key == "registrykeyvalue" and len(values) == 2:
            return "%s=%s" % (values[0], values[1])
        elif key == "socketaddress" and len(values) == 3:
            return "%s:%s/%s" % (values[0], values[1], values[2])
        elif key == "c2_socketaddress" and len(values) == 3:
            return "%s:%s/%s" % (values[0], values[1], values[2])
        elif key == "service" and len(values) == 5:
            return "%s, %s, %s, %s, %s" % (values[0], values[1], values[2], values[3], values[4])
        else:
            return ' '.join(values)

    def print_keyvalue(self, key, value):
        printkey = key

        if sys.stdout.encoding:
            encoding = sys.stdout.encoding
        else:
            encoding = "utf8"

        if isinstance(value, basestring):
            print((u'%-20s %s' % (printkey, value)).encode(encoding, 'backslashreplace'))
        else:
            for item in value:
                if isinstance(item, basestring):
                    print((u'%-20s %s' % (printkey, item)).encode(encoding, 'backslashreplace'))
                else:
                    print(
                        (u'%-20s %s' % (printkey, self.format_list(item, key=key))).encode(encoding,
                                                                                           'backslashreplace'))
                printkey = ""

    def output_text(self):
        """Output in human readable report format
        """

        infoorderlist = INFO_FIELD_ORDER
        fieldorderlist = STANDARD_FIELD_ORDER

        if 'inputfilename' in self.metadata:
            print("\n----File Information----\n")
            for key in infoorderlist:
                if key in self.metadata:
                    self.print_keyvalue(key, self.metadata[key])

        print("\n----Standard Metadata----\n")

        for key in fieldorderlist:
            if key in self.metadata:
                self.print_keyvalue(key, self.metadata[key])
        # in case we have additional fields in fields.json but the order is not updated
        for key in self.metadata:
            if key not in fieldorderlist and key not in ["other", "debug", "outputfile"] and key in self.fields:
                self.print_keyvalue(key, self.metadata[key])

        if "other" in self.metadata:
            print("\n----Other Metadata----\n")
            for key in sorted(list(self.metadata["other"])):
                self.print_keyvalue(key, self.metadata["other"][key])

        if "debug" in self.metadata:
            print("\n----Debug----\n")
            # self.print_keyvalue("debug",self.metadata["debug"])
            for item in self.metadata["debug"]:
                print(item)

        if "outputfile" in self.metadata:
            print("\n----Output Files----\n")
            for key, value in self.metadata["outputfile"]:
                self.print_keyvalue(key, value)

        if self.errors:
            print("\n----Errors----\n")
            for item in self.errors:
                print(item)

    def __redirect_stdout(self):
        # we redirect stdout during execution of parser to trap the output
        self.__debug_stdout = cStringIO.StringIO()
        sys.stdout = self.__debug_stdout

    def __return_stdout(self):
        sys.stdout = self.__orig_stdout
        if not self.__disabledebug:
            for line in self.__debug_stdout.getvalue().splitlines():
                self.add_metadata("debug", line)
        self.__debug_stdout = cStringIO.StringIO()

    def __reset(self):
        """
        Reset all the data in the reporter object that is set during the run_parser function

        Goal is to make the reporter safe to use for multiple run_parser instances
        """
        self.__filename = ''
        self.__tempfilename = ''
        self.__managed_tempdir = ''

        self.data = ''
        self.handle = None

        self.metadata = {}
        self.outputfiles = {}
        self.errors = []
        self.pe = None

    def __cleanup(self):
        """
        Cleanup things
        """
        if not self.__disabletempcleanup:
            if self.__tempfilename:
                try:
                    os.remove(self.__tempfilename)
                except Exception as e:
                    self.debug("Failed to purge temp file: %s, %s" % (self.__tempfilename, str(e)))
                self.__tempfilename = ''
            if self.__managed_tempdir:
                try:
                    shutil.rmtree(self.__managed_tempdir, ignore_errors=True)
                except Exception as e:
                    self.debug("Failed to purge temp dir: %s, %s" % (self.__managed_tempdir, str(e)))
                self.__managed_tempdir = ''

        self.__tempfilename = ''
        self.__managed_tempdir = ''

    def __del__(self):
        self.__cleanup()
